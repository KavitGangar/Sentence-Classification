{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1emPR0JlLmc",
        "outputId": "474a4e1c-5b23-47d7-f141-7e7b5a1354d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, Conv2D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "import nltk\n",
        "import string\n",
        "from string import digits\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHZ4vcVDvAy"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from string import digits\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGeyos-YtLWx"
      },
      "source": [
        "#Loading the dataset and assigning labels\n",
        "\n",
        "data=pd.read_csv('/content/a.txt',sep=\"\\n\",header=None,names=['Examples'])\n",
        "labels=[0]*data.size\n",
        "data.insert(1,\"label\",labels)\n",
        "data1=pd.read_csv('/content/q.txt',sep=\"\\n\",header=None,names=['Examples'])\n",
        "labels=[1]*data1.size\n",
        "data1.insert(1,\"label\",labels)\n",
        "data=data.append(data1)\n",
        "data['Examples']=data['Examples'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu-PIJGpvb1T"
      },
      "source": [
        "#Data cleaning\n",
        "\n",
        "def clean_text(text):\n",
        "    #print(text)\n",
        "    ## Remove puncuation\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    translator = str.maketrans('','',digits)\n",
        "    text=text.translate(translator)\n",
        "    \n",
        "    ## Convert words to lower case and split them\n",
        "    text = text.lower()\n",
        "    \n",
        "    \n",
        "    ## Remove stop words\n",
        "    #stops = set(stopwords.words(\"english\"))\n",
        "    #text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    \n",
        "    #text = \"\\n\".join([ll.rstrip() for ll in text.splitlines() if ll.strip()])\n",
        "    #text = \" \".join(text)\n",
        "    #text.replaceAll(\"\\\\d\",\"\")\n",
        "    #text = filter(lambda x: not re.match(r'^\\s*$', x), text)\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"\\n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \"\", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" \", text)\n",
        "    text = re.sub(r\"\\+\", \" \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text) \n",
        "    \"\"\"\n",
        "    ## Stemming\n",
        "    \n",
        "    #text = text.split()\n",
        "    #stemmer = SnowballStemmer('english')\n",
        "    #stemmed_words = [stemmer.stem(word) for word in text]\n",
        "    #text = \" \".join(stemmed_words)\n",
        "    \n",
        "    text=re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO2NDadOl4NJ"
      },
      "source": [
        "#More data pre-processing and removing empty sentences\n",
        "\n",
        "data['Examples'] = data['Examples'].map(lambda x: clean_text(x))\n",
        "data['Examples'].replace('',np.nan,inplace=True)\n",
        "data=data.dropna()\n",
        "data['Examples']=data['Examples'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLjXAVGI2CPn",
        "outputId": "d4cae7dc-67ea-4b30-da8b-43a30d8d47c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#for using ktrain library to use bert\n",
        "\n",
        "data['Statement']=data['label']\n",
        "for i in range(len(data)) :\n",
        "    if data['label'].iloc[i]==0:\n",
        "        data['Statement'].iloc[i]=1\n",
        "    else:\n",
        "        data['Statement'].iloc[i]=0\n",
        "\n",
        "\n",
        "data=data.rename(columns={'label':'Question'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxO0LiV45bmD",
        "outputId": "eae54851-34c4-4ffd-a2e3-0f1f4e60cab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#Bert model using ktrain library\n",
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(data, \n",
        "                                                                   'Examples', # name of column containing review text\n",
        "                                                                   label_columns=['Question', 'Statement'],\n",
        "                                                                   maxlen=75, \n",
        "                                                                   max_features=100000,\n",
        "                                                                   preprocess_mode='bert',\n",
        "                                                                   val_pct=0.33,\n",
        "                                                                   ngram_range=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8prWxQcaFijl",
        "outputId": "7f818caf-39e6-495b-9d97-bc4afd307a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = text.text_classifier('bert', (x_train, y_train) , preproc=preproc)\n",
        "learner = ktrain.get_learner(model, \n",
        "                             train_data=(x_train, y_train), \n",
        "                             val_data=(x_test, y_test), \n",
        "                             batch_size=32)\n",
        "\n",
        "#learner.lr_find(show_plot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 75\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1KXgCDI3zeo"
      },
      "source": [
        "model = learner.load_model('/content/drive/My Drive/SentenceClassification/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBoq-c9t57mK",
        "outputId": "53bd3d3a-b7da-4b39-e1b3-72cf5fd5108a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "learner.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     43073\n",
            "           1       1.00      1.00      1.00     37410\n",
            "\n",
            "    accuracy                           1.00     80483\n",
            "   macro avg       1.00      1.00      1.00     80483\n",
            "weighted avg       1.00      1.00      1.00     80483\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42971,   102],\n",
              "       [   80, 37330]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M3FaDYNJhwR",
        "outputId": "3f825587-79ae-46aa-c198-89b6c12e3573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "learner.fit_onecycle(1e-6, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-06...\n",
            "Train on 163404 samples, validate on 80483 samples\n",
            "163404/163404 [==============================] - 4118s 25ms/sample - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.0099 - val_accuracy: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fcfbc5908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1daFym1chr2K"
      },
      "source": [
        "learner.save_model('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeZ_S_Rhg6Bk"
      },
      "source": [
        "learner.view_top_losses(n=1, preproc=preproc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEEiwnlLXs5f",
        "outputId": "26e26d37-6a36-4d10-ca7f-a38660ab8056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#dataP has sentences which are ambiguous for the model to predict. The test set has sentences similar to the train set hence to test the quality of classification of the model, these sentences are tested.\n",
        "\n",
        "predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "predictor.save('/content/drive/My Drive/Glove')\n",
        "dataP = [\n",
        "        'This can be done by us',\n",
        "        'This is not what is expected from you',\n",
        "        'Dont do this',\n",
        "        'This is a statement',\n",
        "        'Predict this as a statement',\n",
        "        'I am a guy',\n",
        "        'What is you name',\n",
        "        'Why cant you do this',\n",
        "        'This is why I cant do this',\n",
        "         'This is not how you should behave',\n",
        "         'Why I cant do this',\n",
        "         'Why cant I do this',\n",
        "         'Why should you be doing this',\n",
        "         'This is why you should be doing this'\n",
        "         ]\n",
        "\n",
        "#here, Question => Statement, Statement => Question (Labels were interchanged while training BERT model)\n",
        "predictor.predict(dataP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Question',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Statement',\n",
              " 'Statement',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Question',\n",
              " 'Statement',\n",
              " 'Statement',\n",
              " 'Question']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgyPSPLBjHFS",
        "outputId": "90d9ff78-24cb-49e9-dec4-c6efce7bf098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#using count vectorizer to convert words to vectors\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=20000).fit(data['Examples'])\n",
        "X = vectorizer.transform(data['Examples'])\n",
        "Y=data.iloc[:,1]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "print(X_train.shape)\n",
        "#X_train=X_train.toarray()\n",
        "#X_test=X_test.toarray()\n",
        "#To count the frequency of each word in the corpus for deciding the vocabulary depending on the counts\n",
        "'''\n",
        "sum_words=X.sum(axis=0)\n",
        "vectorizer.vocabulary_.items()\n",
        "words_freq = [(word, sum_words[0, idx]) for word, idx in     vectorizer.vocabulary_.items()]\n",
        "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "words_freq[19000:20000]\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(163404, 20000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nsum_words=X.sum(axis=0)\\nvectorizer.vocabulary_.items()\\nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vectorizer.vocabulary_.items()]\\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\\nwords_freq[19000:20000]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fc0C-525GKr",
        "outputId": "96f96099-59dd-4164-9d7b-b12af81217c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Using tf-idf for converting words to vectors\n",
        "\n",
        "Tfidf_vect = TfidfVectorizer(max_features=20000)\n",
        "Tfidf_vect.fit(data['Examples'])\n",
        "X=data.iloc[:,0]\n",
        "Y=data.iloc[:,1]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "print(X_train.shape)\n",
        "X_train = Tfidf_vect.transform(X_train)\n",
        "X_test = Tfidf_vect.transform(X_test)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(163404,)\n",
            "(163404, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdPt4xX5yYA",
        "outputId": "f6d764aa-4a1c-4959-bf35-7e732e210d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# fit the training dataset on the NB classifier\n",
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(X_train,Y_train)\n",
        "# predict the labels on test dataset\n",
        "predictions_NB = Naive.predict(X_test)\n",
        "\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_NB, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_NB, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_NB, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_NB, Y_test*100))\n",
        "print(confusion_matrix(predictions_NB, Y_test))\n",
        "tn, fp, fn, tp = confusion_matrix(predictions_NB, Y_test).ravel()\n",
        "tn,fp,fn,tp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  84.20536013816582\n",
            "Naive Bayes Accuracy Score ->  98.27271677635378\n",
            "Naive Bayes Accuracy Score ->  78.05616184589425\n",
            "Naive Bayes Accuracy Score ->  87.00549956044405\n",
            "Naive Bayes Accuracy Score ->  0.8758751394043421\n",
            "[[25214   748]\n",
            " [11964 42557]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25214, 748, 11964, 42557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7meQiCh9qHow",
        "outputId": "a5211ed5-9e3e-4e5a-9ed3-efaf594a2cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Training using random Forest algorithm\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=15, random_state=0)\n",
        "clf.fit(X_train,Y_train)\n",
        "clf.score(X_test,Y_test)\n",
        "predictions_RF=clf.predict(X_test)\n",
        "\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_RF, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_RF, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_RF, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_RF, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_RF, Y_test)*100)\n",
        "print(confusion_matrix(predictions_RF, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  95.25365605158854\n",
            "Naive Bayes Accuracy Score ->  97.36750952545896\n",
            "Naive Bayes Accuracy Score ->  94.02385996209165\n",
            "Naive Bayes Accuracy Score ->  95.66647759500852\n",
            "Naive Bayes Accuracy Score ->  95.41251362771511\n",
            "[[34498  1140]\n",
            " [ 2680 42165]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1U6vgIx7XKh",
        "outputId": "10c505ed-a820-453e-97b5-499096b41b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Classifier Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(X_train,Y_train)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(X_test)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_SVM, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_SVM, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_SVM, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_SVM, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_SVM, Y_test)*100)\n",
        "print(confusion_matrix(predictions_SVM, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  98.98487879427954\n",
            "Naive Bayes Accuracy Score ->  98.98487879427954\n",
            "Naive Bayes Accuracy Score ->  98.90081976677058\n",
            "Naive Bayes Accuracy Score ->  99.21009960620802\n",
            "Naive Bayes Accuracy Score ->  99.05521827117663\n",
            "Naive Bayes Accuracy Score ->  98.96720240407417\n",
            "[[36837   476]\n",
            " [  341 42829]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydgCDAegGsYq",
        "outputId": "f1a8ac89-5ffe-455d-d8af-85afd70f9d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "#Using CNN with tf-idf/count vectorizers\n",
        "\n",
        "model_conv = Sequential()\n",
        "'''\n",
        "model_conv.add(Conv1D(64, 5, activation='relu',input_shape=(20000,1)))\n",
        "model_conv.add(MaxPooling1D(pool_size=4))\n",
        "model_conv.add(LSTM(100))\n",
        "'''\n",
        "model_conv.add(Dense(100, activation='relu',input_shape=(20000,)))\n",
        "model_conv.add(Dense(1, activation='sigmoid'))\n",
        "model_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_conv.summary()\n",
        "model_conv.fit(X_train, Y_train, validation_split=0.2, epochs = 5)\n",
        "model_conv.evaluate(X_test,Y_test)\n",
        "\n",
        "predictions_CNN = model_conv.predict(X_test)\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_CNN, Y_test)*100)\n",
        "print(confusion_matrix(predictions_CNN, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               2000100   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,000,201\n",
            "Trainable params: 2,000,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 130723 samples, validate on 32681 samples\n",
            "Epoch 1/5\n",
            "130723/130723 [==============================] - 39s 296us/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.0408 - val_accuracy: 0.9881\n",
            "Epoch 2/5\n",
            "130723/130723 [==============================] - 37s 283us/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.0404 - val_accuracy: 0.9882\n",
            "Epoch 3/5\n",
            "130723/130723 [==============================] - 37s 282us/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0441 - val_accuracy: 0.9877\n",
            "Epoch 4/5\n",
            "130723/130723 [==============================] - 38s 289us/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0500 - val_accuracy: 0.9876\n",
            "Epoch 5/5\n",
            "130723/130723 [==============================] - 37s 286us/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0564 - val_accuracy: 0.9875\n",
            "80483/80483 [==============================] - 10s 130us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6eb8b06a8efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredictions_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVM Accuracy Score -> \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Naive Bayes Accuracy Score -> \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYr4Qz12ndH",
        "outputId": "8510497d-216e-472c-8af4-cf9adaf8ba95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "predictions_CNN = model_conv.predict_classes(X_test)\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_CNN, Y_test)*100)\n",
        "print(confusion_matrix(predictions_CNN, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  98.81962650497621\n",
            "Naive Bayes Accuracy Score ->  98.81962650497621\n",
            "Naive Bayes Accuracy Score ->  99.05784551437479\n",
            "Naive Bayes Accuracy Score ->  98.75227330279243\n",
            "Naive Bayes Accuracy Score ->  98.90482338836117\n",
            "Naive Bayes Accuracy Score ->  98.8254401823324\n",
            "[[36636   408]\n",
            " [  542 42897]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVcMkFsz81Rc",
        "outputId": "3d0f9d7d-3616-48ea-a340-93c20f4b37ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "sent=[\n",
        "        'This can be done by us',\n",
        "        'This is not what is expected from you',\n",
        "        'Dont do this',\n",
        "        'This is a statement',\n",
        "        'Predict this as a statement',\n",
        "        'I am a guy',\n",
        "        'What is you name',\n",
        "        'Why cant you do this',\n",
        "        'This is why I cant do this',\n",
        "         'This is not how you should behave',\n",
        "         'Why I cant do this',\n",
        "         'Why cant I do this',\n",
        "         'Why should you be doing this',\n",
        "         'This is why you should be doing this'\n",
        "         ]\n",
        "ans=Tfidf_vect.transform(sent)\n",
        "print(clf.predict(ans))\n",
        "print(SVM.predict(ans))\n",
        "print(Naive.predict(ans))\n",
        "print(model_conv.predict_classes(ans))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 0 0 0 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3f674d9d5b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_3_input to have shape (50,) but got array with shape (20000,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhOcXDCQ3tUD"
      },
      "source": [
        "#Saving models\n",
        "\n",
        "filename = '/content/drive/My Drive/Glove/SVMmodel.sav'\n",
        "pickle.dump(SVM, open(filename, 'wb')) \n",
        "\n",
        "filename = '/content/drive/My Drive/Glove/NaiveBayesmodel.sav'\n",
        "pickle.dump(Naive, open(filename, 'wb')) \n",
        "\n",
        "filename = '/content/drive/My Drive/Glove/CNNmodel.sav'\n",
        "pickle.dump(model_conv, open(filename, 'wb')) \n",
        "\n",
        "\n",
        "filename = '/content/drive/My Drive/Glove/RandomForestmodel.sav'\n",
        "pickle.dump(clf, open(filename, 'wb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c2XTK4cq7tX",
        "outputId": "15882136-278e-4c73-f275-72e5dfd8b1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary_size = 30000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(data['Examples'])\n",
        "len(tokenizer.word_index)+ 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BggogB_K158x",
        "outputId": "80a09e8d-9186-44c0-de16-1bcecfcb7855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#For using pre-trained word embeddings (Preparing embedding Matrix)\n",
        "test=list()\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/My Drive/SentenceClassification/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    test.append(values[0])\n",
        "    words = values[0]\n",
        "    if(words == 'destiny'):\n",
        "        print('present')\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[words] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
        "count=0\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector\n",
        "        else:\n",
        "            count=count+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai2KLRlA5GtP",
        "outputId": "94329793-d6b9-4e8b-f93a-ec7b4ba14915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Tokenising and data splitting\n",
        "\n",
        "X=data.iloc[:,0]\n",
        "Y=data.iloc[:,1]\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "X = pad_sequences(sequences, maxlen=50)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163404, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9dvCNQOEjCQ",
        "outputId": "226e0d0e-76a3-485a-b8aa-87db2824d9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "#Model that uses keras's embedding layer directly\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(20000, 100, input_length=50))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(X_train, Y_train, validation_split=0.2, epochs=5,batch_size=128)\n",
        "model.evaluate(X_test,Y_test)\n",
        "\n",
        "predictions_CNN=model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 50, 100)           2000000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,080,501\n",
            "Trainable params: 2,080,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 130723 samples, validate on 32681 samples\n",
            "Epoch 1/5\n",
            "130723/130723 [==============================] - 175s 1ms/step - loss: 0.0628 - accuracy: 0.9786 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
            "Epoch 2/5\n",
            "130723/130723 [==============================] - 174s 1ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
            "Epoch 3/5\n",
            "130723/130723 [==============================] - 175s 1ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
            "Epoch 4/5\n",
            "130723/130723 [==============================] - 174s 1ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0377 - val_accuracy: 0.9909\n",
            "Epoch 5/5\n",
            "130723/130723 [==============================] - 177s 1ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0350 - val_accuracy: 0.9916\n",
            "80483/80483 [==============================] - 31s 391us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK7CvgW6qU7p"
      },
      "source": [
        "#Model with a convolution layer ahead of LSTM layer inorder to reduce training time by using filters in CNN\n",
        "\n",
        "model_conv = Sequential()\n",
        "model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
        "model_conv.add(Dropout(0.2))\n",
        "model_conv.add(Conv1D(64, 5, activation='relu'))\n",
        "model_conv.add(MaxPooling1D(pool_size=4))\n",
        "model_conv.add(LSTM(100))\n",
        "model_conv.add(Dense(1, activation='sigmoid'))\n",
        "model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
        "model_conv.fit(X_train, Y_train, validation_split=0.2, epochs = 3)\n",
        "model_conv.evaluate(X_test,Y_test)\n",
        "\n",
        "predictions_CNN=model_conv.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyr8MG0HrKcj",
        "outputId": "064cdf9f-db1a-4766-bedc-4d58932b4f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "#Model using pre-trained word embeddings\n",
        "\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
        "'''\n",
        "model_glove.add(Dropout(0.2))\n",
        "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "'''\n",
        "model_glove.add(LSTM(100))\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_glove.summary()\n",
        "model_glove.fit(X_train,Y_train, validation_split=0.2, epochs = 7,batch_size=512)\n",
        "model_glove.evaluate(X_test,Y_test)\n",
        "\n",
        "predictions_CNN=model_glove.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 300)           9000000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 9,160,501\n",
            "Trainable params: 160,501\n",
            "Non-trainable params: 9,000,000\n",
            "_________________________________________________________________\n",
            "Train on 130723 samples, validate on 32681 samples\n",
            "Epoch 1/7\n",
            "130723/130723 [==============================] - 25s 190us/step - loss: 0.1159 - accuracy: 0.9544 - val_loss: 0.0422 - val_accuracy: 0.9861\n",
            "Epoch 2/7\n",
            "130723/130723 [==============================] - 23s 179us/step - loss: 0.0345 - accuracy: 0.9883 - val_loss: 0.0315 - val_accuracy: 0.9904\n",
            "Epoch 3/7\n",
            "130723/130723 [==============================] - 23s 177us/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0271 - val_accuracy: 0.9917\n",
            "Epoch 4/7\n",
            "130723/130723 [==============================] - 23s 179us/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0249 - val_accuracy: 0.9932\n",
            "Epoch 5/7\n",
            "130723/130723 [==============================] - 23s 177us/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0252 - val_accuracy: 0.9926\n",
            "Epoch 6/7\n",
            "130723/130723 [==============================] - 23s 174us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0232 - val_accuracy: 0.9935\n",
            "Epoch 7/7\n",
            "130723/130723 [==============================] - 23s 179us/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0258 - val_accuracy: 0.9933\n",
            "80483/80483 [==============================] - 21s 255us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygz9GfqNSMwJ",
        "outputId": "e40858ab-6306-4639-dac8-3f2091f43cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",precision_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",recall_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",f1_score(predictions_CNN, Y_test)*100)\n",
        "print(\"Naive Bayes Accuracy Score -> \",roc_auc_score(predictions_CNN, Y_test)*100)\n",
        "print(confusion_matrix(predictions_CNN, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  99.32780835704435\n",
            "Naive Bayes Accuracy Score ->  99.32780835704435\n",
            "Naive Bayes Accuracy Score ->  99.30723934880498\n",
            "Naive Bayes Accuracy Score ->  99.44272302640707\n",
            "Naive Bayes Accuracy Score ->  99.3749350094164\n",
            "Naive Bayes Accuracy Score ->  99.31853636617237\n",
            "[[36937   300]\n",
            " [  241 43005]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m75l_VclcyKX",
        "outputId": "6cd467dc-2f10-4062-a534-a40c0113afc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "sent=[\n",
        "        'This can be done by us',\n",
        "        'This is not what is expected from you',\n",
        "        'Dont do this',\n",
        "        'This is a statement',\n",
        "        'Predict this as a statement',\n",
        "        'I am a guy',\n",
        "        'What is you name',\n",
        "        'Why cant you do this',\n",
        "        'This is why I cant do this',\n",
        "         'This is not how you should behave',\n",
        "         'Why I cant do this',\n",
        "         'Why cant I do this',\n",
        "         'Why should you be doing this',\n",
        "         'This is why you should be doing this'\n",
        "         ]\n",
        "seq=tokenizer.texts_to_sequences(sent)\n",
        "test = pad_sequences(seq, maxlen=50)\n",
        "model_glove.predict_classes(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6MUW6uksxBq"
      },
      "source": [
        "filename = '/content/drive/My Drive/SentenceClassification/CNNGloveembeddingmodel.sav'\n",
        "pickle.dump(model_glove, open(filename, 'wb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKoGwiE_tDQ4",
        "outputId": "275bdac7-307d-4147-9a55-c56cfe55190d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sent=[\"in the barbie world\"]\n",
        "ans=Tfidf_vect.transform(sent)\n",
        "Naive.predict(ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYze3JihJfxl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}